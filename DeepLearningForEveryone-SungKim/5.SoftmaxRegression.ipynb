{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae79f5fd-6db4-423a-9fcf-6aa260e0ab06",
   "metadata": {},
   "source": [
    "# SoftmaxRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac07dd4d-f462-4c18-b4d8-88e72c21a9cc",
   "metadata": {},
   "source": [
    "**Logostic regression**  \n",
    "분류해야할 데이터들이 여러차원으로 표현 되어 있을 때  \n",
    "이 데이터들을 구분하는 선을 찾는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6e90d4-ff8e-4ef2-a2a4-593e8086dd1c",
   "metadata": {},
   "source": [
    "**Multinomial classification**\n",
    "위 아이디어를 그대로 가져와서 여러가지 경우를 분류하는 것  \n",
    "Binary Classification으로도 구현 가능  \n",
    "예시)  \n",
    "X -> A인지 아닌지 확힌하는 Classifier  \n",
    "X -> B인지 아닌지 확힌하는 Classifier  \n",
    "X -> C인지 아닌지 확힌하는 Classifier  \n",
    "통과 시 세 그룹으로 분류 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972c1550-e5b8-4a3f-a736-b7ba21ee34d5",
   "metadata": {},
   "source": [
    "이때 예시에서 각각 WX의 합을 구하여 분류하는 과정(Classifier통과)를 하나로 묶으면  \n",
    "기존 $W X = w_1x_1 + w_2x_2 ... w_nx_n$과 같던 식이  \n",
    "하나로 변함  \n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "w_{11} & w_{12} & w_{13} \\\\ \n",
    "w_{21} & w_{22} & w_{23} \\\\\n",
    "w_{31} & w_{32} & w_{33}\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix} \n",
    "x_{1} \\\\ \n",
    "x_{2} \\\\ \n",
    "x_{3} \n",
    "\\end{bmatrix} \n",
    "= \\begin{bmatrix} \n",
    "w_{11}x_1 + w_{12}x_2 + w_{13}x_3 \\\\ \n",
    "w_{21}x_1 + w_{22}x_2 + w_{23}x_3 \\\\\n",
    "w_{31}x_1 + w_{32}x_2 + w_{33}x_3\n",
    "\\end{bmatrix}\n",
    "$$  \n",
    "이때 하나하나의 행($w_{11}x_1 + w_{12}x_2 + w_{13}x_3$ 등)을 종합적으로 판단하기 위한 도구 필요  \n",
    "따라서 시그모이드 함수 적용 후  \n",
    "시그모이드의 을 다 받아서 총합이 1이 되는 값들로 변환  \n",
    "이때 사용 되는 것이 SOFTMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e329322-f7ca-4e0f-839c-144c43f6e78e",
   "metadata": {},
   "source": [
    "$$ S(y_i) = \\frac{e^{y_i}}{\\sum_j e^{y_j}}$$  \n",
    "여기서 나온 값을 받아 argmax를 적용(OneHotEncoding)해줌으로서 분류 완료  \n",
    "$$\n",
    "Y\n",
    "\\begin{bmatrix}\n",
    "2.0 \\\\\n",
    "1.0 \\\\\n",
    "0.1 \n",
    "\\end{bmatrix}\n",
    "\\rightarrow\n",
    "S(y)\n",
    "\\rightarrow\n",
    "P\n",
    "\\begin{bmatrix}\n",
    "0.7 \\\\\n",
    "0.2 \\\\\n",
    "0.1 \n",
    "\\end{bmatrix}\n",
    "\\rightarrow\n",
    "argmax\n",
    "\\rightarrow\n",
    "L\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "0 \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60122cea-f998-481d-9a46-87ca67352508",
   "metadata": {},
   "source": [
    "**Cost Function**\n",
    "**Cross-Entropy**  \n",
    "S(y) 와 L을 사용한 손실함수  \n",
    "$$D(S,L) = -\\sum_{i} L_i \\log(S_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c51764d-c9a4-4a09-9856-6c606d2b4d44",
   "metadata": {},
   "source": [
    "-log는 0과 1사이의 값만 받을 수 있고  \n",
    "이는 통과 시 틀린 정답에 대해 강력한 손실값을 반환해 주고  \n",
    "맞는 정답에 대해서는 손실값으로 0반환  \n",
    "따라서 손실함수로서 적합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6eb134-ba28-41f7-8f6f-e98c905f17f2",
   "metadata": {},
   "source": [
    "지난 챕터의 Logistc Cost  \n",
    "$c(H(x), y) = -y\\log(H(x)) -(1-y)\\log(1-H(x))$ 와 구조적으로 동일함  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33d3d57a-2c4b-4215-8d83-94e2a2f66370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(777)\n",
    "\n",
    "x_data = [[1, 2, 1, 1],\n",
    "          [2, 1, 3, 2],\n",
    "          [3, 1, 3, 4],\n",
    "          [4, 1, 5, 5],\n",
    "          [1, 7, 5, 5],\n",
    "          [1, 2, 5, 6],\n",
    "          [1, 6, 6, 6],\n",
    "          [1, 7, 7, 7]]\n",
    "\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74b1fa0d-9845-4a84-a8c5-f2c3203f8412",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.cast(x_data, tf.float32)\n",
    "y_train = tf.cast(y_data, tf.float32)\n",
    "\n",
    "nb_classes = 3\n",
    "\n",
    "W = tf.Variable(tf.random.normal([4, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([nb_classes]), name='bias')\n",
    "\n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "def hypothesis(X):\n",
    "    return tf.nn.softmax(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74ef3a1-630d-4134-be7b-66a630c19c20",
   "metadata": {},
   "source": [
    "입력값에 가중치를 곱하고 편향을 더한 계산값이  \n",
    "softmax를 통과하며 최종적으로 내놓는 답은 확률로 표현 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3402daf4-a17d-46ad-9eab-43f98e9dc6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_fn(X, Y):\n",
    "    logits = hypothesis(X)\n",
    "    cost_i = tf.reduce_sum(Y * tf.math.log(logits + 1e-7), axis=1)\n",
    "    return tf.reduce_mean(-cost_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b54c72-9720-4b5b-8981-b158e1a17b19",
   "metadata": {},
   "source": [
    "$D(S,L) = -\\sum_{i} L_i \\log(S_i)$에 H(x)값 넘겨 주는 것 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e13bff5-c18d-40ab-9b84-7712337f041b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t4.456855\n",
      "200\t0.524867\n",
      "400\t0.416868\n",
      "600\t0.335701\n",
      "800\t0.261106\n",
      "1000\t0.229923\n",
      "1200\t0.208102\n",
      "1400\t0.190058\n",
      "1600\t0.174857\n",
      "1800\t0.161866\n",
      "2000\t0.150633\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    with tf.GradientTape() as tape:\n",
    "        curr_cost = cost_fn(x_train, y_train)\n",
    "\n",
    "    grads = tape.gradient(curr_cost, [W, b])\n",
    "    optimizer.apply_gradients(zip(grads, [W, b]))\n",
    "\n",
    "    if step % 200 == 0:\n",
    "        print(f'{step}\\t{curr_cost.numpy():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f922681-d2a2-4aaf-a164-abff403a0bf5",
   "metadata": {},
   "source": [
    "학습 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "199db5c6-ee64-4747-9285-62c406a2aa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.3327835e-03 9.9865854e-01 8.6538557e-06]]\n",
      "Predict: [1]\n",
      "[[0.93171006 0.0628916  0.00539825]]\n",
      "Predict: [0]\n",
      "[[1.0695679e-08 3.2634559e-04 9.9967372e-01]]\n",
      "Predict: [2]\n",
      "[[3.91332151e-06 1.05971191e-03 9.98936355e-01]\n",
      " [2.99250358e-03 8.31682459e-02 9.13839221e-01]\n",
      " [2.79758083e-08 1.61043167e-01 8.38956773e-01]\n",
      " [8.45727811e-07 8.51096332e-01 1.48902804e-01]\n",
      " [2.43110850e-01 7.44687140e-01 1.22020217e-02]\n",
      " [1.27047539e-01 8.72940838e-01 1.16033225e-05]\n",
      " [7.68399298e-01 2.31578097e-01 2.26548218e-05]\n",
      " [9.20781970e-01 7.92177096e-02 3.84079527e-07]]\n",
      "Predict: [2 2 2 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "test_data = tf.cast([[1, 11, 7, 9]], tf.float32)\n",
    "a = hypothesis(test_data)\n",
    "print(f\"{a.numpy()}\\nPredict: {tf.argmax(a, axis=1).numpy()}\") \n",
    "\n",
    "test_data = tf.cast([[1, 3, 4, 3]], tf.float32)\n",
    "b_pred = hypothesis(test_data)\n",
    "print(f\"{b_pred.numpy()}\\nPredict: {tf.argmax(b_pred, axis=1).numpy()}\") \n",
    "\n",
    "test_data = tf.cast([[1, 1, 0, 1]], tf.float32)\n",
    "c = hypothesis(test_data)\n",
    "print(f\"{c.numpy()}\\nPredict: {tf.argmax(c, axis=1).numpy()}\") \n",
    "\n",
    "all_pred = hypothesis(x_train)\n",
    "print(f\"{all_pred.numpy()}\\nPredict: {tf.argmax(all_pred, axis=1).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb96caa-e56c-4e4f-be0f-c47fafc373c4",
   "metadata": {},
   "source": [
    "**Fancy Softmax Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ed67ec-716e-46af-ac9b-870e37962314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchResearch",
   "language": "python",
   "name": "torchresearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
