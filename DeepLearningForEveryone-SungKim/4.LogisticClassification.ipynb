{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcaa9cb7-6463-4b00-97c9-f9bc264e174f",
   "metadata": {},
   "source": [
    "# LogisticClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b105fa2c-b5db-4a38-a41b-6afb911b7531",
   "metadata": {},
   "source": [
    "Binary Classification : 두가지로 분류  \n",
    "대표적 예 : 스펨 메일 분류, 페이스북 알고리즘, Finance 등"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adce0e69-40d2-429d-ab46-b14260ded33c",
   "metadata": {},
   "source": [
    "Linear Regression가 분류에서 가지는 한계  \n",
    "* 특잇값 때문에 왜곡이 일어날 수 있음  \n",
    "* 0,1 외에 너무 큰 값을 반환할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd45a9c6-7aa5-4d03-9bd1-976aefc03adc",
   "metadata": {},
   "source": [
    "따라서 0,1사이의 값을 주는 함수를 찾음  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c33c1f-b0c2-4469-ab28-8ce58417aaab",
   "metadata": {},
   "source": [
    " 시그모이드 $$ g(z) = \\frac{1}{1+ e^{-z}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1adbb6a-ab08-4a2e-a30a-b52317a27135",
   "metadata": {},
   "source": [
    "이제 Hypothesis를  \n",
    "$ z = WX $  \n",
    "$ H(x) = g(z) $  \n",
    "즉, $$ H(X) = \\frac{1}{1+ e^{-W^TX}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9918bf7-832f-455a-8e24-ad6a38dea623",
   "metadata": {},
   "source": [
    "기존 손실함수는  \n",
    "$$ Cost = \\frac{1}{m} \\sum_{i=1}^m (H(x_i) - y_i)^2) $$  \n",
    "이때 이를 바꾼 $H(x)$에 대해 그대로 적용하면 Convex하지 않고 울퉁불퉁한 그래프 모양이 나옴  \n",
    "이때 Local minimum이 많이 생기기 때문에 Global minimun으로 학습이 되지 않음  \n",
    "따라서 다른 손실 함수 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7b062b-4184-449b-9771-8a6fb9362869",
   "metadata": {},
   "source": [
    "**New cost function for logistic**\n",
    "$$ cost(W) = \\frac{1}{m} \\sum c(H(x),y) $$\n",
    "$$c(H(x), y) = \\begin{cases} \n",
    "-\\log(H(x)) & y=1 \\\\ \n",
    "-\\log(1-H(x)) & y=0 \n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194e370c-e8d1-4c5e-a6f7-07b516c8f942",
   "metadata": {},
   "source": [
    "**해석**  \n",
    "자연상수e가 함수 모양을 울퉁불퉁하게 만들기에 log를 활용하여 매끄럽게 바꿔줌  \n",
    "실제레이블이 1일때\n",
    "* 예측값이 1로 맞았을때는 cost값이 0  \n",
    "* 예측값이 0으로 틀렸을때는 cost값이 무한히 발산  \n",
    "\n",
    "실제레이블이 0일때\n",
    "* 예측값이 0으로 맞았을때는 cost값이 0  \n",
    "* 예측값이 1로 틀렸을때는 cost값이 무한히 발산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d13297-5387-4548-9dc6-b1d400954751",
   "metadata": {},
   "source": [
    "이는 case로 쪼개져 있으므로 손실함수로 프로그램에 사용하기 위해 한줄로 표현시  \n",
    "$$ cost(W) = \\frac{1}{m} \\sum c(H(x),y) $$\n",
    "$$c(H(x), y) = -y\\log(H(x)) -(1-y)\\log(1-H(x))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503ee77f-6dbc-4f1e-a7c7-32018a740167",
   "metadata": {},
   "source": [
    "데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dd71fa7-7561-41ca-b448-02df2b111fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[1, 2],\n",
    "          [2, 3],\n",
    "          [3, 1],\n",
    "          [4, 3],\n",
    "          [5, 3],\n",
    "          [6, 2]]\n",
    "y_data = [[0],\n",
    "          [0],\n",
    "          [0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [1]]\n",
    "\n",
    "x_data = tf.cast(x_data, tf.float32)\n",
    "y_data = tf.cast(y_data, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05a4153-df55-4155-a6a8-6ff35206fece",
   "metadata": {},
   "source": [
    "가중치와 편향 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d90a4b8-8cc4-4f2f-b493-9ede919271a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random.normal([2, 1]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117bf347-a1f4-4158-88fa-5a03c89a870e",
   "metadata": {},
   "source": [
    "가설 (Hypothesis): Sigmoid 함수 적용  \n",
    "$ H(x) = \\frac{1}{(1 + exp^{-(Wx + b)}} $  \n",
    "\n",
    "비용 함수 (Cost function) 적용  \n",
    "$cost(H(x), y) = -y\\log(H(x)) -(1-y)\\log(1-H(x))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d10cd6a9-1d4c-4840-adee-f99e95c10a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6118011\n",
      "200 0.4231594\n",
      "400 0.36791316\n",
      "600 0.33932242\n",
      "800 0.32137775\n",
      "1000 0.3082878\n",
      "1200 0.2976899\n",
      "1400 0.2885197\n",
      "1600 0.28025836\n",
      "1800 0.27263513\n",
      "2000 0.26549995\n",
      "2200 0.25876418\n",
      "2400 0.25237182\n",
      "2600 0.24628502\n",
      "2800 0.2404759\n",
      "3000 0.23492311\n",
      "3200 0.22960901\n",
      "3400 0.22451837\n",
      "3600 0.21963787\n",
      "3800 0.21495533\n",
      "4000 0.21045978\n",
      "4200 0.20614094\n",
      "4400 0.20198917\n",
      "4600 0.19799584\n",
      "4800 0.19415258\n",
      "5000 0.19045155\n",
      "5200 0.18688555\n",
      "5400 0.18344784\n",
      "5600 0.18013185\n",
      "5800 0.17693168\n",
      "6000 0.17384155\n",
      "6200 0.1708563\n",
      "6400 0.16797084\n",
      "6600 0.16518043\n",
      "6800 0.16248076\n",
      "7000 0.15986751\n",
      "7200 0.15733679\n",
      "7400 0.15488493\n",
      "7600 0.15250836\n",
      "7800 0.15020382\n",
      "8000 0.1479681\n",
      "8200 0.14579828\n",
      "8400 0.1436916\n",
      "8600 0.14164531\n",
      "8800 0.13965698\n",
      "9000 0.13772428\n",
      "9200 0.13584487\n",
      "9400 0.13401668\n",
      "9600 0.1322376\n",
      "9800 0.13050577\n",
      "10000 0.12881935\n",
      "\n",
      "Hypothesis: \n",
      " [[0.02254861]\n",
      " [0.14599545]\n",
      " [0.26286733]\n",
      " [0.8012864 ]\n",
      " [0.95141846]\n",
      " [0.9842107 ]] \n",
      "Correct (Y): \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = tf.sigmoid(tf.matmul(x_data, W) + b)\n",
    "\n",
    "        cost = -tf.reduce_mean(y_data * tf.math.log(hypothesis) + (1 - y_data) * tf.math.log(1 - hypothesis))\n",
    "\n",
    "    grads = tape.gradient(cost, [W, b])\n",
    "    optimizer.apply_gradients(zip(grads, [W, b]))\n",
    "\n",
    "    if step % 200 == 0:\n",
    "        print(step, cost.numpy())\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(x_data, W) + b)\n",
    "\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y_data), dtype=tf.float32))\n",
    "\n",
    "print(\"\\nHypothesis: \\n\", hypothesis.numpy(), \n",
    "      \"\\nCorrect (Y): \\n\", predicted.numpy(), \n",
    "      \"\\nAccuracy: \", accuracy.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8527502-525c-448f-b77c-fd8757d050cb",
   "metadata": {},
   "source": [
    "요약  \n",
    "H(x) = WX는 이진분류에 적합하지 않음  \n",
    "따라서 0과 1사이의 값을 돌려주는 함수를 찾은 것이이 시그모이드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9adce3-3e0b-4935-82c7-2a3701b49d27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchResearch",
   "language": "python",
   "name": "torchresearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
